comment: "isolated training config medium standard, distance reward only, resetUponCollision"
# "Trying with fixed light settings and variable timesteps, we want to see learning progress again. Did something break?"
# we should also try it with the fixed spawn to be closer to the evaluation scenario, maybe the differential can do it 


n_envs: 10


copy_model_from: False
# copy_model_from can be False or a string (filename without .zip suffix)

total_timesteps: 6500000 # restricted to 650000 due to real time limit (about 5 hours per training)

seed: 2048

eval_settings:
  interval_during_learn: 1000
  n_eval_episodes: 100
  eval_light_settings: True
  eval_only: True
  number_eval_runs: 2

algo_settings:
  n_epochs: 5 # amount of training passes over the replay buffer per timestep

  batch_size: 64

  n_steps: 256 # 64 
# amount of steps to collect per collect_rollouts per environment
# Tensorboard shows the mean_episode_length is below 3
# we can reduce the n_steps to make the collection time shorter while still collecting a lot of episodes
# n_steps * fixedTimestepsLength = the amount of seconds required for the collection

  policy: "CnnPolicy"
  use_bundled_calls: True
  use_fresh_obs: False

  print_network_and_loss_structure: False

  net_arch:
    pi: []
    vf: []
  # set pi and vf to [] to use the default CNN policy without fully connected layers

  # since we use the CNN Policy the extractor consists of the nature CNN
  # if we do not define pi and vf, there are no layers after the (cnn) extractor
  # https://github.com/DLR-RM/stable-baselines3/blob/8b3723c6d8420bb978f4d68409ff5189f87fe107/stable_baselines3/common/policies.py#L496-L502
  # we cannot define the cnn structure ourselves if we use the NatureCnn class



env_kwargs:
  jetBotName: DifferentialJetBot
  spawnOrientation: OrientationRandom
  # spawnOrientation can be Fixed, OrientationRandom, OrientationVeryRandom and FullyRandom
  frame_stacking: 10
  image_preprocessing:
    downsampling_factor: 2
    grayscale: True
    equalize: True
    normalize_images: False
  coefficients:
    distanceCoefficient: 1
    orientationCoefficient: 0
    velocityCoefficient: 0
    eventCoefficient: 0
  collisionMode: resetUponCollision
  # unrestricted, oncePerTimestep, oncePerEpisode, resetUponCollision, ignoreCollisions
  trainingMapType: randomEvalMedium
  trainingLightSetting: standard
  # random, bright, standard, dark
  fixedTimestepsLength: 0.3
  # non fixed with 10 envs takes 0.5 seconds for vecenv_step --> this results in 1 fps (per env)

  # fixedTimestepsLength can either be False or a number (seconds that each timestep contains)
  # 2024-02-04/11-56-53 used non-fixed timesteps and had 0.4 fps per environment
  # this run achgieved the highest accuracies yet --> we can increase the duration of fixed timesteps to above a second

  width: 500 #800 #500 #336
  height: 168

