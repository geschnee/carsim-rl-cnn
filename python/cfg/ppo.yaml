comment: "base for isolated training runs"


n_envs: 10
seed: 2048
copy_model_from: False

total_timesteps: 6500000


eval_settings:
  n_eval_episodes: 20
  eval_light_settings: True
  eval_only: False
  number_eval_runs: 3

episode_record_replay_settings:
  n_episodes_per_setting: 1
  deterministic_sampling: True
  replay_folder: False
  # replay_folder can be False to replay the previously recorded episodes



algo_settings:
  n_epochs: 5
  batch_size: 64

  n_steps: 256

  use_bundled_calls: True
  use_fresh_obs: False
  policy: "CnnPolicy"
  print_network_and_loss_structure: True
  net_arch:
    pi: []
    vf: []
  # set pi and vf to [] to use the default CNN policy without fully connected layers
  # since we use the CNN Policy the extractor consists of the nature CNN
  # if we do not define pi and vf, there are no layers after the (cnn) extractor
  # https://github.com/DLR-RM/stable-baselines3/blob/8b3723c6d8420bb978f4d68409ff5189f87fe107/stable_baselines3/common/policies.py#L496-L502
  # we cannot define the cnn structure ourselves if we use the NatureCnn class



env_kwargs:
  jetBotName: DifferentialJetBot
  spawnOrientation: Random
  frame_stacking: 10
  image_preprocessing:
    downsampling_factor: 2
    grayscale: True
    equalize: True
  coefficients:
    distanceCoefficient: 1
    orientationCoefficient: 0
    velocityCoefficient: 0
    eventCoefficient: 1
  collisionMode: oncePerTimestep
  trainingMapType: randomEval
  trainingLightSetting: standard
  fixedTimestepsLength: 0.3
  agentImageWidth: 500
  agentImageHeight: 168

